{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project Submission\n",
    "\n",
    "* Student name: Vikas Bansal\n",
    "* Student pace: part time\n",
    "* Instructor name: Lindsey Berlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convolutional Neural Network Classification Model:\n",
    "\n",
    "\n",
    "My intent with this project was to build a simple deep learning neural network that would be capable of performing binary classification on Chest X-Ray Images s from Kaggle.com. I had to import a module that would serve as an operating system interface from python in the form of os in order to interact directly with the directories located on my computer. Keras was used extensively in this project in order to make use of all of its deep learning capabilities. Numpy was used in the manipulation of images in the form of arrays. Pandas and Matplotlib, were utilized in the exploratory phase of this project in order to visualize the data.\n",
    "\n",
    "I started with importing the necessary modules and libraries needed for this project. I then went ahead and performed the rudimentary data exploration phase by reading in some images as examples of what the data looks like.  I then went ahead and created simple histograms and pie charts comparing people with and without pneumonia lung disease in each of the 3 directories (train, test, and val). Arguably, the most difficult part of this project was constructing the deep learning convolutional neural network to classify the images. I played around with certain parameters in terms of batch size and epochs. There were a lot of moving pieces when it came to initializing this model in order to make it the most efficient possible. I made use of sigmoid and relu activation functions.In conclusion, I would say that the models turned out unsatisfactory for the use case, and I'd like expand on this work in the future and see if there is any way I could descrease the loss at all and increase the accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will adopt the workflow as listed below:\n",
    "\n",
    "1. Obtain (import the data from kaggle's Competition Page)\n",
    "2. Scrub (clean the data, deal with missing values and data types) (Refer to the EDA Notebook)\n",
    "3. Convert the DCIM Image data to jpg (Refer to the jpg conversion notebook)\n",
    "3. Explore (answer descriptives questions using EDA) (Refer to the EDA Notebook)\n",
    "4. Modeling (build our predictive models)\n",
    "5. Interpret (comment on our model and findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Files Information (From Kaggle Competiiton Page)\n",
    "\n",
    "* train_study_level.csv - the train study-level metadata, with one row for each study, including correct labels.\n",
    "* train_image_level.csv - the train image-level metadata, with one row for each image, including both correct labels and any bounding boxes in a dictionary format. Some images in both test and train have multiple bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install colorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "\n",
    "\n",
    "#from pydicom import dcmread\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "res = Style.RESET_ALL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the data to Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTrain image level csv shape : (6334, 4)\u001b[0m\n",
      "\u001b[32mTrain study level csv shape : (6054, 5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "image_df = pd.read_csv('train_image_level.csv', index_col=None)\n",
    "study_df = pd.read_csv('train_study_level.csv', index_col=None)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"{y_}Train image level csv shape : {image_df.shape}{res}\\n{g_}Train study level csv shape : {study_df.shape}{res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00292f8c37bd_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005057b3f880_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0051d9b12e72_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>ffcb4630f46f_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>ffe4d6e8fbb0_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>ffe94fcb14fa_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>ffebf1ef4a9c_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>fff649d65f62_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6054 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  Negative for Pneumonia  Typical Appearance  \\\n",
       "0     00086460a852_study                       0                   1   \n",
       "1     000c9c05fd14_study                       0                   0   \n",
       "2     00292f8c37bd_study                       1                   0   \n",
       "3     005057b3f880_study                       1                   0   \n",
       "4     0051d9b12e72_study                       0                   0   \n",
       "...                  ...                     ...                 ...   \n",
       "6049  ffcb4630f46f_study                       0                   1   \n",
       "6050  ffe4d6e8fbb0_study                       0                   1   \n",
       "6051  ffe94fcb14fa_study                       0                   1   \n",
       "6052  ffebf1ef4a9c_study                       0                   1   \n",
       "6053  fff649d65f62_study                       0                   1   \n",
       "\n",
       "      Indeterminate Appearance  Atypical Appearance  \n",
       "0                            0                    0  \n",
       "1                            0                    1  \n",
       "2                            0                    0  \n",
       "3                            0                    0  \n",
       "4                            0                    1  \n",
       "...                        ...                  ...  \n",
       "6049                         0                    0  \n",
       "6050                         0                    0  \n",
       "6051                         0                    0  \n",
       "6052                         0                    0  \n",
       "6053                         0                    0  \n",
       "\n",
       "[6054 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview Study Dataframe\n",
    "study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2_image</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc_image</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f_image</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891_image</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961_image</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609</td>\n",
       "      <td>7eed9af03814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680_image</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f_image</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0     000a312787f2_image   \n",
       "1     000c3a3f293f_image   \n",
       "2     0012ff7358bc_image   \n",
       "3     001398f4ff4f_image   \n",
       "4     001bd15d1891_image   \n",
       "...                  ...   \n",
       "6329  ffcc6edd9445_image   \n",
       "6330  ffd91a2c4ca0_image   \n",
       "6331  ffd9b6cf2961_image   \n",
       "6332  ffdc682f7680_image   \n",
       "6333  ffe942c8655f_image   \n",
       "\n",
       "                                                                                                                                                                                                                                    boxes  \\\n",
       "0                                                                             [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                   [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                                                                                                       [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                                                                                                      [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "...                                                                                                                                                                                                                                   ...   \n",
       "6329                                                                                                                                                                                                                                  NaN   \n",
       "6330                                                                                                                                                                                                                                  NaN   \n",
       "6331  [{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]   \n",
       "6332                                                                           [{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]   \n",
       "6333                                                                                  [{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]   \n",
       "\n",
       "                                                                                                                                                                               label  \\\n",
       "0                                                                            opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                                                                                                     none 1 0 0 1 1   \n",
       "2                                                                             opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                                                                                                    opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4                                                                                      opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "...                                                                                                                                                                              ...   \n",
       "6329                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6330                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609   \n",
       "6332                                                               opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048   \n",
       "6333                                                                              opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119   \n",
       "\n",
       "     StudyInstanceUID  \n",
       "0        5776db0cec75  \n",
       "1        ff0879eb20ed  \n",
       "2        9d514ce429a7  \n",
       "3        28dddc8559b2  \n",
       "4        dfd9fdd85a3e  \n",
       "...               ...  \n",
       "6329     7e6c68462e06  \n",
       "6330     8332bdaddb6e  \n",
       "6331     7eed9af03814  \n",
       "6332     a0cb0b96fb3d  \n",
       "6333     7d82d53204b8  \n",
       "\n",
       "[6334 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview Image Dataframe\n",
    "image_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we did some EDA earlier on, Lets visualize the Study_df Dataframe in a pivot table, in order to see what labels we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Typical Appearance</td>\n",
       "      <td>2855</td>\n",
       "      <td>#DCD427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative for Pneumonia</td>\n",
       "      <td>1676</td>\n",
       "      <td>#0092CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indeterminate Appearance</td>\n",
       "      <td>1049</td>\n",
       "      <td>#CC3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atypical Appearance</td>\n",
       "      <td>474</td>\n",
       "      <td>#E6E6E6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  value    color\n",
       "0        Typical Appearance   2855  #DCD427\n",
       "1    Negative for Pneumonia   1676  #0092CC\n",
       "2  Indeterminate Appearance   1049  #CC3333\n",
       "3       Atypical Appearance    474  #E6E6E6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_grp = pd.melt(study_df, id_vars=list(study_df.columns)[:1], value_vars=list(study_df.columns)[1:],\n",
    "             var_name='label', value_name='value')\n",
    "study_grp = study_grp.loc[study_grp['value']!=0]\n",
    "colors = {'Typical Appearance' : '#DCD427',\n",
    "'Negative for Pneumonia' : '#0092CC',\n",
    "'Indeterminate Appearance' : '#CC3333',\n",
    "#'Atypical Appearance' : '#779933',\n",
    "          'Atypical Appearance' : '#E6E6E6'\n",
    "         }\n",
    "\n",
    "study_grp = study_grp.groupby('label').sum().sort_values('value',ascending=False).reset_index()\n",
    "study_grp['color'] = study_grp['label'].apply(lambda x: colors[x])\n",
    "study_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imageID  \\\n",
       "0  000a312787f2   \n",
       "1  000c3a3f293f   \n",
       "2  0012ff7358bc   \n",
       "3  001398f4ff4f   \n",
       "4  001bd15d1891   \n",
       "\n",
       "                                                                                                                                                         boxes  \\\n",
       "0  [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                          NaN   \n",
       "2        [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                            [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                           [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "\n",
       "                                                                                                     label  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                           none 1 0 0 1 1   \n",
       "2   opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                          opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4            opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "\n",
       "  StudyInstanceUID  negative  typical  indeterminate  atypical    target  \n",
       "0     5776db0cec75         0        1              0         0   typical  \n",
       "1     ff0879eb20ed         1        0              0         0  negative  \n",
       "2     9d514ce429a7         0        1              0         0   typical  \n",
       "3     28dddc8559b2         0        0              0         1  atypical  \n",
       "4     dfd9fdd85a3e         0        1              0         0   typical  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging study_level and image_level\n",
    "# rename id column in study_level to StudyInstanceUID\n",
    "study_df.rename(columns = {'id':'StudyInstanceUID'}, inplace = True)\n",
    "\n",
    "# remove _study from StudyInstanceUID\n",
    "study_df['StudyInstanceUID'] = study_df['StudyInstanceUID'].str.replace('_study', '')\n",
    "\n",
    "# merge\n",
    "df_train = pd.merge(image_df, study_df, on='StudyInstanceUID')\n",
    "\n",
    "# remove _image from id column\n",
    "df_train['id'] = df_train['id'].str.replace('_image', '')\n",
    "\n",
    "# rename id column as imageID\n",
    "df_train.rename(columns = {'id':'imageID'}, inplace = True)\n",
    "\n",
    "# renaming target columns\n",
    "df_train.rename(columns = {'Negative for Pneumonia':'negative'}, inplace = True)\n",
    "df_train.rename(columns = {'Typical Appearance':'typical'}, inplace = True)\n",
    "df_train.rename(columns = {'Indeterminate Appearance':'indeterminate'}, inplace = True)\n",
    "df_train.rename(columns = {'Atypical Appearance':'atypical'}, inplace = True)\n",
    "\n",
    "# Create a new target column\n",
    "categories = ['negative','typical','indeterminate','atypical']\n",
    "df = df_train[categories]\n",
    "df_train[\"target\"] = pd.Series(df.columns[np.where(df!=0)[1]])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Import the X-Ray jpg images from the local folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNumber of train images: \u001b[32m 6334\n",
      "\n",
      "\u001b[33mNumber of test images: \u001b[32m 1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_jpg_directory = \"/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train\"\n",
    "test_jpg_directory = \"/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/test\"\n",
    "\n",
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "train_images_path = getImagePaths(train_jpg_directory)\n",
    "test_images_path = getImagePaths(test_jpg_directory)\n",
    "\n",
    "print(f\"{y_}Number of train images: {g_} {len(train_images_path)}\\n\")\n",
    "print(f\"{y_}Number of test images: {g_} {len(test_images_path)}\\n\")\n",
    "\n",
    "def getShape(data, images_paths):\n",
    "    shape = cv2.imread(images_paths[0]).shape\n",
    "    for image_path in images_paths:\n",
    "        image_shape=cv2.imread(image_path).shape\n",
    "        if (image_shape!=shape):\n",
    "            return data +\" - Different image shape\"\n",
    "        else:\n",
    "            return data +\" - Same image shape \" + str(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train - Same image shape (256, 256, 3)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getShape('train',train_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test - Same image shape (256, 256, 3)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getShape('test',test_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_images = DataFrame(train_images_path,columns=['train_images_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get a dataframe which has the imageID, Image Name, and the path. For this, lets use the slicer function to get the image ID and image Name from the Image Path Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>imageID</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/d3ab6de09006.jpg</td>\n",
       "      <td>d3ab6de09006</td>\n",
       "      <td>d3ab6de09006.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/cb308b57472a.jpg</td>\n",
       "      <td>cb308b57472a</td>\n",
       "      <td>cb308b57472a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/503563d744a1.jpg</td>\n",
       "      <td>503563d744a1</td>\n",
       "      <td>503563d744a1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/bfb1ffabaaff.jpg</td>\n",
       "      <td>bfb1ffabaaff</td>\n",
       "      <td>bfb1ffabaaff.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ea56a7479090.jpg</td>\n",
       "      <td>ea56a7479090</td>\n",
       "      <td>ea56a7479090.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/36625db2640a.jpg</td>\n",
       "      <td>36625db2640a</td>\n",
       "      <td>36625db2640a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/2b97a6619f32.jpg</td>\n",
       "      <td>2b97a6619f32</td>\n",
       "      <td>2b97a6619f32.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/68bc7bc6ad65.jpg</td>\n",
       "      <td>68bc7bc6ad65</td>\n",
       "      <td>68bc7bc6ad65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/6713c2b6c0a6.jpg</td>\n",
       "      <td>6713c2b6c0a6</td>\n",
       "      <td>6713c2b6c0a6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/4e94dc5b7c52.jpg</td>\n",
       "      <td>4e94dc5b7c52</td>\n",
       "      <td>4e94dc5b7c52.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/d3ab6de09006.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/cb308b57472a.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/503563d744a1.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/bfb1ffabaaff.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ea56a7479090.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/36625db2640a.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/2b97a6619f32.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/68bc7bc6ad65.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/6713c2b6c0a6.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/4e94dc5b7c52.jpg   \n",
       "\n",
       "           imageID        Image_Name  \n",
       "0     d3ab6de09006  d3ab6de09006.jpg  \n",
       "1     cb308b57472a  cb308b57472a.jpg  \n",
       "2     503563d744a1  503563d744a1.jpg  \n",
       "3     bfb1ffabaaff  bfb1ffabaaff.jpg  \n",
       "4     ea56a7479090  ea56a7479090.jpg  \n",
       "...            ...               ...  \n",
       "6329  36625db2640a  36625db2640a.jpg  \n",
       "6330  2b97a6619f32  2b97a6619f32.jpg  \n",
       "6331  68bc7bc6ad65  68bc7bc6ad65.jpg  \n",
       "6332  6713c2b6c0a6  6713c2b6c0a6.jpg  \n",
       "6333  4e94dc5b7c52  4e94dc5b7c52.jpg  \n",
       "\n",
       "[6334 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_images['imageID'] = df_train_images['train_images_path'].str.slice(98,110)\n",
    "df_train_images['Image_Name'] = df_train_images['train_images_path'].str.slice(98,114)\n",
    "df_train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.merge(df_train,df_train_images, on='imageID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "      <th>target</th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg</td>\n",
       "      <td>000a312787f2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg</td>\n",
       "      <td>000c3a3f293f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg</td>\n",
       "      <td>0012ff7358bc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>atypical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg</td>\n",
       "      <td>001398f4ff4f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg</td>\n",
       "      <td>001bd15d1891.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg</td>\n",
       "      <td>ffcc6edd9445.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg</td>\n",
       "      <td>ffd91a2c4ca0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609</td>\n",
       "      <td>7eed9af03814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg</td>\n",
       "      <td>ffd9b6cf2961.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg</td>\n",
       "      <td>ffdc682f7680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg</td>\n",
       "      <td>ffe942c8655f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           imageID  \\\n",
       "0     000a312787f2   \n",
       "1     000c3a3f293f   \n",
       "2     0012ff7358bc   \n",
       "3     001398f4ff4f   \n",
       "4     001bd15d1891   \n",
       "...            ...   \n",
       "6329  ffcc6edd9445   \n",
       "6330  ffd91a2c4ca0   \n",
       "6331  ffd9b6cf2961   \n",
       "6332  ffdc682f7680   \n",
       "6333  ffe942c8655f   \n",
       "\n",
       "                                                                                                                                                                                                                                    boxes  \\\n",
       "0                                                                             [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                   [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                                                                                                       [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                                                                                                      [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "...                                                                                                                                                                                                                                   ...   \n",
       "6329                                                                                                                                                                                                                                  NaN   \n",
       "6330                                                                                                                                                                                                                                  NaN   \n",
       "6331  [{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]   \n",
       "6332                                                                           [{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]   \n",
       "6333                                                                                  [{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]   \n",
       "\n",
       "                                                                                                                                                                               label  \\\n",
       "0                                                                            opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                                                                                                     none 1 0 0 1 1   \n",
       "2                                                                             opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                                                                                                    opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4                                                                                      opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "...                                                                                                                                                                              ...   \n",
       "6329                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6330                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609   \n",
       "6332                                                               opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048   \n",
       "6333                                                                              opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119   \n",
       "\n",
       "     StudyInstanceUID  negative  typical  indeterminate  atypical    target  \\\n",
       "0        5776db0cec75         0        1              0         0   typical   \n",
       "1        ff0879eb20ed         1        0              0         0  negative   \n",
       "2        9d514ce429a7         0        1              0         0   typical   \n",
       "3        28dddc8559b2         0        0              0         1  atypical   \n",
       "4        dfd9fdd85a3e         0        1              0         0   typical   \n",
       "...               ...       ...      ...            ...       ...       ...   \n",
       "6329     7e6c68462e06         1        0              0         0  negative   \n",
       "6330     8332bdaddb6e         1        0              0         0  negative   \n",
       "6331     7eed9af03814         0        1              0         0   typical   \n",
       "6332     a0cb0b96fb3d         0        1              0         0   typical   \n",
       "6333     7d82d53204b8         0        1              0         0   typical   \n",
       "\n",
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg   \n",
       "\n",
       "            Image_Name  \n",
       "0     000a312787f2.jpg  \n",
       "1     000c3a3f293f.jpg  \n",
       "2     0012ff7358bc.jpg  \n",
       "3     001398f4ff4f.jpg  \n",
       "4     001bd15d1891.jpg  \n",
       "...                ...  \n",
       "6329  ffcc6edd9445.jpg  \n",
       "6330  ffd91a2c4ca0.jpg  \n",
       "6331  ffd9b6cf2961.jpg  \n",
       "6332  ffdc682f7680.jpg  \n",
       "6333  ffe942c8655f.jpg  \n",
       "\n",
       "[6334 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets drop columns we do not need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final.drop(['boxes', 'label', 'StudyInstanceUID', 'typical', 'indeterminate', 'atypical', 'target', 'imageID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg</td>\n",
       "      <td>000a312787f2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg</td>\n",
       "      <td>000c3a3f293f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg</td>\n",
       "      <td>0012ff7358bc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg</td>\n",
       "      <td>001398f4ff4f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg</td>\n",
       "      <td>001bd15d1891.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg</td>\n",
       "      <td>ffcc6edd9445.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg</td>\n",
       "      <td>ffd91a2c4ca0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg</td>\n",
       "      <td>ffd9b6cf2961.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg</td>\n",
       "      <td>ffdc682f7680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg</td>\n",
       "      <td>ffe942c8655f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     negative  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           0   \n",
       "3           0   \n",
       "4           0   \n",
       "...       ...   \n",
       "6329        1   \n",
       "6330        1   \n",
       "6331        0   \n",
       "6332        0   \n",
       "6333        0   \n",
       "\n",
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg   \n",
       "\n",
       "            Image_Name  \n",
       "0     000a312787f2.jpg  \n",
       "1     000c3a3f293f.jpg  \n",
       "2     0012ff7358bc.jpg  \n",
       "3     001398f4ff4f.jpg  \n",
       "4     001bd15d1891.jpg  \n",
       "...                ...  \n",
       "6329  ffcc6edd9445.jpg  \n",
       "6330  ffd91a2c4ca0.jpg  \n",
       "6331  ffd9b6cf2961.jpg  \n",
       "6332  ffdc682f7680.jpg  \n",
       "6333  ffe942c8655f.jpg  \n",
       "\n",
       "[6334 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview Final Dataframe, before we do the train test split\n",
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6334 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Since we need to get our image data in the format that we can feed to our CNN models, lets use the train_generator function with the Flow_from_dataframe attribute.  \n",
    "df_train_final['negative'] = df_train_final['negative'].astype('str')\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.6, 1.3],\n",
    "    shear_range=0.3,\n",
    "    #zoom_range=[0.8, 1.0],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                                        dataframe=df_train_final,\n",
    "                                        directory='/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train',\n",
    "                                        x_col='Image_Name',\n",
    "                                        y_col='negative',\n",
    "                                        class_mode='binary',\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test data sets\n",
    "\n",
    "X = df_train_final.loc[:,'Image_Name']\n",
    "y = df_train_final.loc[:,'negative']\n",
    "\n",
    "# Split\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, \n",
    "                                                  test_size = 0.1, \n",
    "                                                  random_state = 27, \n",
    "                                                  stratify=y)\n",
    "\n",
    "# Train df\n",
    "df_train = pd.DataFrame(columns=['Image_Name','negative'])\n",
    "df_train['Image_Name'] = train_x\n",
    "df_train['negative'] = train_y\n",
    "\n",
    "# Test df\n",
    "df_test= pd.DataFrame(columns=['image_name','negative'])\n",
    "df_test['image_name'] = val_x\n",
    "df_test['negative'] = val_y\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7c46483f6ef9.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0edcec25f01f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66a513ecac8f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00e3a7e91a34.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72039153a0dd.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2da7581bab1e.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>3d6c5fa4b95e.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>35ad423bca61.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>c8f42ce79d67.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>3b31c91dd63b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name negative\n",
       "0    7c46483f6ef9.jpg        0\n",
       "1    0edcec25f01f.jpg        0\n",
       "2    66a513ecac8f.jpg        0\n",
       "3    00e3a7e91a34.jpg        1\n",
       "4    72039153a0dd.jpg        0\n",
       "..                ...      ...\n",
       "629  2da7581bab1e.jpg        0\n",
       "630  3d6c5fa4b95e.jpg        0\n",
       "631  35ad423bca61.jpg        0\n",
       "632  c8f42ce79d67.jpg        1\n",
       "633  3b31c91dd63b.jpg        0\n",
       "\n",
       "[634 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/'\n",
    "\n",
    "# Images and labels\n",
    "train_images = df_train.loc[:,'Image_Name']\n",
    "train_labels = df_train.loc[:,'negative']\n",
    "\n",
    "test_images = df_test.loc[:,'image_name']\n",
    "test_labels = df_test.loc[:,'negative']\n",
    "\n",
    "# Trai n images\n",
    "x_train = []\n",
    "for i in train_images:\n",
    "    image = home_path+i\n",
    "    img = cv2.imread(image)\n",
    "    x_train.append(img)\n",
    "\n",
    "# Train and Test labels\n",
    "y_train = np.array(train_labels, dtype=\"float\")\n",
    "y_test = np.array(test_labels, dtype=\"float\")\n",
    "y_train=keras.utils.to_categorical(train_labels)\n",
    "y_test=keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Test images\n",
    "x_test = []\n",
    "for i in test_images:\n",
    "    image = home_path+i \n",
    "    img = cv2.imread(image)\n",
    "    x_test.append(img)\n",
    "\n",
    "# Normalize images\n",
    "x_train = np.array(x_train, dtype=\"float\") / 255.0\n",
    "x_test = np.array(x_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5695    1\n",
       "5696    0\n",
       "5697    0\n",
       "5698    0\n",
       "5699    0\n",
       "Name: negative, Length: 5700, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 256, 256, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 256, 256, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5700\n",
      "Number of testing samples: 634\n",
      "train_images shape: (5700, 256, 256, 3)\n",
      "train_labels shape: (5700, 2)\n",
      "test_images shape: (634, 256, 256, 3)\n",
      "test_labels shape: (634, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore our datasets\n",
    "m_train = x_train.shape[0]\n",
    "num_px = x_train.shape[1]\n",
    "m_test = x_test.shape[0]\n",
    "\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"train_images shape: \" + str(x_train.shape))\n",
    "print (\"train_labels shape: \" + str(y_train.shape))\n",
    "print (\"test_images shape: \" + str(x_test.shape))\n",
    "print (\"test_labels shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image dimensions to be used\n",
    "\n",
    "# specify first channels to represent color channels \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train[:,1], (5700,1))\n",
    "y_test = np.reshape(y_test[:,1], (634,1))\n",
    "#x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.03921569, 0.03921569, 0.03921569],\n",
       "         ...,\n",
       "         [0.08235294, 0.08235294, 0.08235294],\n",
       "         [0.08627451, 0.08627451, 0.08627451],\n",
       "         [0.04705882, 0.04705882, 0.04705882]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.04705882, 0.04705882, 0.04705882],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09803922, 0.09803922, 0.09803922],\n",
       "         [0.05490196, 0.05490196, 0.05490196]],\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         ...,\n",
       "         [0.11764706, 0.11764706, 0.11764706],\n",
       "         [0.11764706, 0.11764706, 0.11764706],\n",
       "         [0.07058824, 0.07058824, 0.07058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.03529412, 0.03529412, 0.03529412],\n",
       "         [0.01568627, 0.01568627, 0.01568627],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.09019608, 0.09019608, 0.09019608],\n",
       "         [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "        [[0.01568627, 0.01568627, 0.01568627],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         ...,\n",
       "         [0.14901961, 0.14901961, 0.14901961],\n",
       "         [0.1372549 , 0.1372549 , 0.1372549 ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.42352941, 0.42352941, 0.42352941],\n",
       "         [0.14509804, 0.14509804, 0.14509804],\n",
       "         [0.02352941, 0.02352941, 0.02352941]],\n",
       "\n",
       "        [[0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         ...,\n",
       "         [0.23137255, 0.23137255, 0.23137255],\n",
       "         [0.09019608, 0.09019608, 0.09019608],\n",
       "         [0.03921569, 0.03921569, 0.03921569]],\n",
       "\n",
       "        [[0.01568627, 0.01568627, 0.01568627],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         ...,\n",
       "         [0.05098039, 0.05098039, 0.05098039],\n",
       "         [0.04705882, 0.04705882, 0.04705882],\n",
       "         [0.06666667, 0.06666667, 0.06666667]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.01568627, 0.01568627, 0.01568627]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.64705882, 0.64705882, 0.64705882],\n",
       "         [0.35686275, 0.35686275, 0.35686275]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.9254902 , 0.9254902 , 0.9254902 ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.7372549 , 0.7372549 , 0.7372549 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.65490196, 0.65490196, 0.65490196],\n",
       "         [0.63137255, 0.63137255, 0.63137255],\n",
       "         [0.61568627, 0.61568627, 0.61568627],\n",
       "         ...,\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941]],\n",
       "\n",
       "        [[0.65098039, 0.65098039, 0.65098039],\n",
       "         [0.63529412, 0.63529412, 0.63529412],\n",
       "         [0.61960784, 0.61960784, 0.61960784],\n",
       "         ...,\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941]],\n",
       "\n",
       "        [[0.52156863, 0.52156863, 0.52156863],\n",
       "         [0.51764706, 0.51764706, 0.51764706],\n",
       "         [0.51372549, 0.51372549, 0.51372549],\n",
       "         ...,\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         ...,\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765]],\n",
       "\n",
       "        [[0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         ...,\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765]],\n",
       "\n",
       "        [[0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         ...,\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.09411765, 0.09411765, 0.09411765]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.81176471, 0.81176471, 0.81176471],\n",
       "         [0.82352941, 0.82352941, 0.82352941],\n",
       "         [0.83529412, 0.83529412, 0.83529412],\n",
       "         ...,\n",
       "         [0.42745098, 0.42745098, 0.42745098],\n",
       "         [0.47058824, 0.47058824, 0.47058824],\n",
       "         [0.52941176, 0.52941176, 0.52941176]],\n",
       "\n",
       "        [[0.81568627, 0.81568627, 0.81568627],\n",
       "         [0.82352941, 0.82352941, 0.82352941],\n",
       "         [0.83921569, 0.83921569, 0.83921569],\n",
       "         ...,\n",
       "         [0.43137255, 0.43137255, 0.43137255],\n",
       "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
       "         [0.50980392, 0.50980392, 0.50980392]],\n",
       "\n",
       "        [[0.81568627, 0.81568627, 0.81568627],\n",
       "         [0.82745098, 0.82745098, 0.82745098],\n",
       "         [0.83921569, 0.83921569, 0.83921569],\n",
       "         ...,\n",
       "         [0.43137255, 0.43137255, 0.43137255],\n",
       "         [0.47058824, 0.47058824, 0.47058824],\n",
       "         [0.49019608, 0.49019608, 0.49019608]]],\n",
       "\n",
       "\n",
       "       [[[0.40392157, 0.40392157, 0.40392157],\n",
       "         [0.38823529, 0.38823529, 0.38823529],\n",
       "         [0.2627451 , 0.2627451 , 0.2627451 ],\n",
       "         ...,\n",
       "         [0.59607843, 0.59607843, 0.59607843],\n",
       "         [0.61568627, 0.61568627, 0.61568627],\n",
       "         [0.64313725, 0.64313725, 0.64313725]],\n",
       "\n",
       "        [[0.20784314, 0.20784314, 0.20784314],\n",
       "         [0.17647059, 0.17647059, 0.17647059],\n",
       "         [0.05882353, 0.05882353, 0.05882353],\n",
       "         ...,\n",
       "         [0.48627451, 0.48627451, 0.48627451],\n",
       "         [0.54509804, 0.54509804, 0.54509804],\n",
       "         [0.59607843, 0.59607843, 0.59607843]],\n",
       "\n",
       "        [[0.24313725, 0.24313725, 0.24313725],\n",
       "         [0.24313725, 0.24313725, 0.24313725],\n",
       "         [0.61568627, 0.61568627, 0.61568627],\n",
       "         ...,\n",
       "         [0.15686275, 0.15686275, 0.15686275],\n",
       "         [0.21960784, 0.21960784, 0.21960784],\n",
       "         [0.2745098 , 0.2745098 , 0.2745098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.36862745, 0.36862745, 0.36862745],\n",
       "         [0.38039216, 0.38039216, 0.38039216],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.05882353, 0.05882353, 0.05882353]],\n",
       "\n",
       "        [[0.36862745, 0.36862745, 0.36862745],\n",
       "         [0.40784314, 0.40784314, 0.40784314],\n",
       "         [0.42352941, 0.42352941, 0.42352941],\n",
       "         ...,\n",
       "         [0.01568627, 0.01568627, 0.01568627],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.07843137, 0.07843137, 0.07843137]],\n",
       "\n",
       "        [[0.41960784, 0.41960784, 0.41960784],\n",
       "         [0.4627451 , 0.4627451 , 0.4627451 ],\n",
       "         [0.47843137, 0.47843137, 0.47843137],\n",
       "         ...,\n",
       "         [0.03921569, 0.03921569, 0.03921569],\n",
       "         [0.04705882, 0.04705882, 0.04705882],\n",
       "         [0.10588235, 0.10588235, 0.10588235]]],\n",
       "\n",
       "\n",
       "       [[[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.08235294, 0.08235294, 0.08235294],\n",
       "         [0.3372549 , 0.3372549 , 0.3372549 ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         ...,\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.07058824, 0.07058824, 0.07058824],\n",
       "         [0.10980392, 0.10980392, 0.10980392],\n",
       "         [0.16078431, 0.16078431, 0.16078431],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.09019608, 0.09019608, 0.09019608],\n",
       "         [0.1254902 , 0.1254902 , 0.1254902 ],\n",
       "         [0.18039216, 0.18039216, 0.18039216],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.10980392, 0.10980392, 0.10980392],\n",
       "         [0.14901961, 0.14901961, 0.14901961],\n",
       "         [0.20392157, 0.20392157, 0.20392157],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 256, 256, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (5700, 256, 256, 3)\n",
      "5700 train samples\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", x_train.shape)\n",
    "print(y_train.shape[0], \"train samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now build a basic CNN model and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = models.Sequential()\n",
    "\n",
    "# Build baseline CNN\n",
    "model_b.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_b.add(layers.MaxPooling2D((2, 2)))\n",
    "model_b.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model_b.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_b.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model_b.add(layers.MaxPooling2D((2, 2)))\n",
    "model_b.add(layers.Flatten())\n",
    "model_b.add(layers.Dense(64, activation='relu'))\n",
    "model_b.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 124, 124, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 7,889,953\n",
      "Trainable params: 7,889,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_3_input')>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_3')>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a binary classification problem, the most suitable loss function to use is binary_crossentropy. We have chosen Nadam as the optimizer as it combines Adam with Nesterov momentum, to maximise speed and likelyhood of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model, select loss function and optimizer to use\n",
    "model_b.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'Nadam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model for 10 epochs, using local CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x1581b3430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x1581b3430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-04 20:01:26.020959: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph MLCSubgraphOp_1_0 with frame_id = 0 and iter_id = 0 with error: Internal: CreateMLCConv2DLayer: Failed to create MLCConvolutionLayer for n23 = sequential_1/conv2d_4/Conv2D (MLCConv2D) (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:01:36.693554: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph gradient_tape/MLCSubgraphOp_1_3 with frame_id = 0 and iter_id = 0 with error: Internal: PerformGradientPassNodeRoutine: Failed to find forward-pass output for node: binary_crossentropy/logistic_loss/MLCSigmoidCrossEntropyWithLogits (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:01:44.858938: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph MLCSubgraphOp_1_0 with frame_id = 0 and iter_id = 0 with error: Internal: CreateMLCConv2DLayer: Failed to create MLCConvolutionLayer for n23 = sequential_1/conv2d_4/Conv2D (MLCConv2D) (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:01:48.678350: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph gradient_tape/MLCSubgraphOp_1_3 with frame_id = 0 and iter_id = 0 with error: Internal: PerformGradientPassNodeRoutine: Failed to find forward-pass output for node: binary_crossentropy/logistic_loss/MLCSigmoidCrossEntropyWithLogits (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:01:55.993997: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph MLCSubgraphOp_1_0 with frame_id = 0 and iter_id = 0 with error: Internal: CreateMLCConv2DLayer: Failed to create MLCConvolutionLayer for n23 = sequential_1/conv2d_4/Conv2D (MLCConv2D) (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:02:03.196014: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph gradient_tape/MLCSubgraphOp_1_3 with frame_id = 0 and iter_id = 0 with error: Internal: PerformGradientPassNodeRoutine: Failed to find forward-pass output for node: binary_crossentropy/logistic_loss/MLCSigmoidCrossEntropyWithLogits (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:02:10.946389: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph MLCSubgraphOp_1_0 with frame_id = 0 and iter_id = 0 with error: Internal: CreateMLCConv2DLayer: Failed to create MLCConvolutionLayer for n23 = sequential_1/conv2d_4/Conv2D (MLCConv2D) (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:02:18.822795: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph gradient_tape/MLCSubgraphOp_1_3 with frame_id = 0 and iter_id = 0 with error: Internal: PerformGradientPassNodeRoutine: Failed to find forward-pass output for node: binary_crossentropy/logistic_loss/MLCSigmoidCrossEntropyWithLogits (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:02:27.151934: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph MLCSubgraphOp_1_0 with frame_id = 0 and iter_id = 0 with error: Internal: CreateMLCConv2DLayer: Failed to create MLCConvolutionLayer for n23 = sequential_1/conv2d_4/Conv2D (MLCConv2D) (error will be reported 5 times unless TF_MLC_LOGGING=1).\n",
      "2021-08-04 20:02:34.294026: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph gradient_tape/MLCSubgraphOp_1_3 with frame_id = 0 and iter_id = 0 with error: Internal: PerformGradientPassNodeRoutine: Failed to find forward-pass output for node: binary_crossentropy/logistic_loss/MLCSigmoidCrossEntropyWithLogits (error will be reported 5 times unless TF_MLC_LOGGING=1).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_46813/2239425379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit model set epochs to ensure convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history_b = model_b.fit(x_train, y_train, epochs = 10, batch_size = 100, verbose = 0,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     validation_data = (x_test, y_test))\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model set epochs to ensure convergence\n",
    "history_b = model_b.fit(x_train, y_train, epochs = 10, batch_size = 100, verbose = 0,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their seems to be some issue with Tensorflow, in running the above model. Lets interrupt the Kernel on this, and move forward with a second iteration of the CNN model and see if the error persists. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Iteration of CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple sequential architecture for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architechture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_6_input')>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking input Shape\n",
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'activation_9')>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Output Shape\n",
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile using Adam as the optimizer. \n",
    "optim = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 19:56:42.386489: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-03 19:56:42.393336: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17ff86940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17ff86940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7255WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x148169700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x148169700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "570/570 [==============================] - 63s 109ms/step - loss: 0.0000e+00 - accuracy: 0.7255 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 2/15\n",
      "570/570 [==============================] - 58s 102ms/step - loss: 0.0000e+00 - accuracy: 0.7273 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 3/15\n",
      "570/570 [==============================] - 61s 108ms/step - loss: 0.0000e+00 - accuracy: 0.7259 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 4/15\n",
      "570/570 [==============================] - 62s 108ms/step - loss: 0.0000e+00 - accuracy: 0.7259 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 5/15\n",
      "570/570 [==============================] - 61s 107ms/step - loss: 0.0000e+00 - accuracy: 0.7341 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 6/15\n",
      "570/570 [==============================] - 62s 109ms/step - loss: 0.0000e+00 - accuracy: 0.7290 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 7/15\n",
      "570/570 [==============================] - 63s 110ms/step - loss: 0.0000e+00 - accuracy: 0.7208 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 8/15\n",
      "570/570 [==============================] - 68s 119ms/step - loss: 0.0000e+00 - accuracy: 0.7359 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 9/15\n",
      "570/570 [==============================] - 65s 113ms/step - loss: 0.0000e+00 - accuracy: 0.7204 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 10/15\n",
      "570/570 [==============================] - 66s 115ms/step - loss: 0.0000e+00 - accuracy: 0.7318 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 11/15\n",
      "570/570 [==============================] - 64s 113ms/step - loss: 0.0000e+00 - accuracy: 0.7268 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 12/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7248 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 13/15\n",
      "570/570 [==============================] - 63s 110ms/step - loss: 0.0000e+00 - accuracy: 0.7286 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 14/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7106 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 15/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7339 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n"
     ]
    }
   ],
   "source": [
    "#Fit\n",
    "history = model.fit(x_train,y_train, epochs = 15, batch_size = 10, verbose = 1,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN Model ran successfully, unlike the first attempt. However, you'd see that the accuracy numbers are not very consistent, as one would generally expect. The Validation set is leading to the same accuracy numbers across all epochs, which does seem irregular. It seems like the validation set is picking up the model minimum value. Lets see how the plots look like, for Accuracy, for both test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_46813/3067790364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot Model's accuracy for train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot Model's accuracy for train and test sets\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph does show a constant line for the validation set, as expected. However, their does seem to be some irregularity with the results of this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Iteration CNN Model Analysis: \n",
    "Analyzing results from this Model: The Accuracy for all epochs seems to be around the 72% mark and does not seem to be improving. The accuracy for the validation set is the exact same across all epochs. We might need to test another model architecture to get better results than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Iteration of the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Third model, we will take it a step further and add attributes to the nodes such as the kernel regularizer. We will also add droputs and increase the Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_12_input')>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Model2 input shape\n",
    "model2.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'activation_14')>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Model2 output shape\n",
    "model2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x11fcd0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x11fcd0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.6973WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x11fcd04c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x11fcd04c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "57/57 [==============================] - 144s 3s/step - loss: 0.0000e+00 - accuracy: 0.6977 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 144s 3s/step - loss: 0.0000e+00 - accuracy: 0.7154 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 146s 3s/step - loss: 0.0000e+00 - accuracy: 0.7225 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 143s 3s/step - loss: 0.0000e+00 - accuracy: 0.7331 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 144s 3s/step - loss: 0.0000e+00 - accuracy: 0.7368 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 144s 3s/step - loss: 0.0000e+00 - accuracy: 0.7359 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 148s 3s/step - loss: 0.0000e+00 - accuracy: 0.7216 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 146s 3s/step - loss: 0.0000e+00 - accuracy: 0.7249 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 138s 2s/step - loss: 0.0000e+00 - accuracy: 0.7228 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 117s 2s/step - loss: 0.0000e+00 - accuracy: 0.7148 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 118s 2s/step - loss: 0.0000e+00 - accuracy: 0.7232 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7218 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7284 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 115s 2s/step - loss: 0.0000e+00 - accuracy: 0.7295 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7162 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n"
     ]
    }
   ],
   "source": [
    "#Compile Model 2\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "#Fit Model 2\n",
    "history2 = model2.fit(x_train,y_train, epochs = 15, batch_size = 100, verbose = 1,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Model2's accuracy for train and test sets\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Iteration CNN Model Analysis: \n",
    "Analyzing results from this Model: The Accuracy for all epochs again seems to be around the same mark and does not seem to be improving. The accuracy for the validation set is the exact same across all epochs once again. We might need to test another model architecture to get better results than this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The results from this project were not conclusive. For the 3 CNN models deployed, the first model had to be interrupted due to a tensorflow warning, that did not let it run. \n",
    "The second model provided an acceptable 72% accuracy, but the constant accuracy of the second model does demand further analysis. The Third CNN model also led to similar results with the Validation set accuracy. \n",
    "\n",
    "The models need to be further developed in order to identify if their are any corrections that must be made in the model architecture or the dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
