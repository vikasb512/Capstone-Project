{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Readme - explain how the three notebooks connect. \n",
    "Talk about what is the scope of work in the project\n",
    "talk about why this project is being done?\n",
    "Talk about the results of the models\n",
    "Increase the epochs of both models\n",
    "Add markdowns for this final notebook\n",
    "Add Future work to be done section with conclusions\n",
    "\n",
    "\n",
    "## Convolutional Neural Network Classification Model:\n",
    "\n",
    "\n",
    "My intent with this project was to build a simple deep learning neural network that would be capable of performing binary classification on Chest X-Ray Images s from Kaggle.com. I had to import a module that would serve as an operating system interface from python in the form of os in order to interact directly with the directories located on my computer. Keras was used extensively in this project in order to make use of all of its deep learning capabilities. Numpy was used in the manipulation of images in the form of arrays. Pandas and Matplotlib, were utilized in the exploratory phase of this project in order to visualize the data.\n",
    "\n",
    "I started with importing the necessary modules and libraries needed for this project. I then went ahead and performed the rudimentary data exploration phase by reading in some images as examples of what the data looks like. I also assigned certain directories to their respective variables in order to make use of them in the visualization and deep learning model building stages. I then went ahead and created simple histograms and pie charts comparing people with and without pneumonia lung disease in each of the 3 directories (train, test, and val). Arguably, the most difficult part of this project was constructing the deep learning convolutional neural network to classify the images. I played around with certain parameters in terms of batch size and epochs. There were a lot of moving pieces when it came to initializing this model in order to make it the most efficient possible. I made use of sigmoid and relu activation functions. The final stage was to evaluate my model and the accuracy percentage turned out to be ~90% and the loss percentage was ~36%. In conclusion, I would say that the model turned out alrigh, although I'd like expand on this work in the future and see if there is any way I could descrease the loss at all. The weights are saved under model_parameters.h5 after running this project in its entirety.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "\n",
    "\n",
    "#from pydicom import dcmread\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "res = Style.RESET_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTrain image level csv shape : (6334, 4)\u001b[0m\n",
      "\u001b[32mTrain study level csv shape : (6054, 5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#PATH = '/kaggle/input/dataf'\n",
    "image_df = pd.read_csv('train_image_level.csv', index_col=None)\n",
    "study_df = pd.read_csv('train_study_level.csv', index_col=None)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"{y_}Train image level csv shape : {image_df.shape}{res}\\n{g_}Train study level csv shape : {study_df.shape}{res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00292f8c37bd_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005057b3f880_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0051d9b12e72_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>ffcb4630f46f_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>ffe4d6e8fbb0_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>ffe94fcb14fa_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>ffebf1ef4a9c_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>fff649d65f62_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6054 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  Negative for Pneumonia  Typical Appearance  \\\n",
       "0     00086460a852_study                       0                   1   \n",
       "1     000c9c05fd14_study                       0                   0   \n",
       "2     00292f8c37bd_study                       1                   0   \n",
       "3     005057b3f880_study                       1                   0   \n",
       "4     0051d9b12e72_study                       0                   0   \n",
       "...                  ...                     ...                 ...   \n",
       "6049  ffcb4630f46f_study                       0                   1   \n",
       "6050  ffe4d6e8fbb0_study                       0                   1   \n",
       "6051  ffe94fcb14fa_study                       0                   1   \n",
       "6052  ffebf1ef4a9c_study                       0                   1   \n",
       "6053  fff649d65f62_study                       0                   1   \n",
       "\n",
       "      Indeterminate Appearance  Atypical Appearance  \n",
       "0                            0                    0  \n",
       "1                            0                    1  \n",
       "2                            0                    0  \n",
       "3                            0                    0  \n",
       "4                            0                    1  \n",
       "...                        ...                  ...  \n",
       "6049                         0                    0  \n",
       "6050                         0                    0  \n",
       "6051                         0                    0  \n",
       "6052                         0                    0  \n",
       "6053                         0                    0  \n",
       "\n",
       "[6054 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2_image</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc_image</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f_image</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891_image</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961_image</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609</td>\n",
       "      <td>7eed9af03814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680_image</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f_image</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0     000a312787f2_image   \n",
       "1     000c3a3f293f_image   \n",
       "2     0012ff7358bc_image   \n",
       "3     001398f4ff4f_image   \n",
       "4     001bd15d1891_image   \n",
       "...                  ...   \n",
       "6329  ffcc6edd9445_image   \n",
       "6330  ffd91a2c4ca0_image   \n",
       "6331  ffd9b6cf2961_image   \n",
       "6332  ffdc682f7680_image   \n",
       "6333  ffe942c8655f_image   \n",
       "\n",
       "                                                                                                                                                                                                                                    boxes  \\\n",
       "0                                                                             [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                   [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                                                                                                       [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                                                                                                      [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "...                                                                                                                                                                                                                                   ...   \n",
       "6329                                                                                                                                                                                                                                  NaN   \n",
       "6330                                                                                                                                                                                                                                  NaN   \n",
       "6331  [{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]   \n",
       "6332                                                                           [{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]   \n",
       "6333                                                                                  [{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]   \n",
       "\n",
       "                                                                                                                                                                               label  \\\n",
       "0                                                                            opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                                                                                                     none 1 0 0 1 1   \n",
       "2                                                                             opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                                                                                                    opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4                                                                                      opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "...                                                                                                                                                                              ...   \n",
       "6329                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6330                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609   \n",
       "6332                                                               opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048   \n",
       "6333                                                                              opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119   \n",
       "\n",
       "     StudyInstanceUID  \n",
       "0        5776db0cec75  \n",
       "1        ff0879eb20ed  \n",
       "2        9d514ce429a7  \n",
       "3        28dddc8559b2  \n",
       "4        dfd9fdd85a3e  \n",
       "...               ...  \n",
       "6329     7e6c68462e06  \n",
       "6330     8332bdaddb6e  \n",
       "6331     7eed9af03814  \n",
       "6332     a0cb0b96fb3d  \n",
       "6333     7d82d53204b8  \n",
       "\n",
       "[6334 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Typical Appearance</td>\n",
       "      <td>2855</td>\n",
       "      <td>#DCD427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative for Pneumonia</td>\n",
       "      <td>1676</td>\n",
       "      <td>#0092CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indeterminate Appearance</td>\n",
       "      <td>1049</td>\n",
       "      <td>#CC3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atypical Appearance</td>\n",
       "      <td>474</td>\n",
       "      <td>#E6E6E6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  value    color\n",
       "0        Typical Appearance   2855  #DCD427\n",
       "1    Negative for Pneumonia   1676  #0092CC\n",
       "2  Indeterminate Appearance   1049  #CC3333\n",
       "3       Atypical Appearance    474  #E6E6E6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_grp = pd.melt(study_df, id_vars=list(study_df.columns)[:1], value_vars=list(study_df.columns)[1:],\n",
    "             var_name='label', value_name='value')\n",
    "study_grp = study_grp.loc[study_grp['value']!=0]\n",
    "colors = {'Typical Appearance' : '#DCD427',\n",
    "'Negative for Pneumonia' : '#0092CC',\n",
    "'Indeterminate Appearance' : '#CC3333',\n",
    "#'Atypical Appearance' : '#779933',\n",
    "          'Atypical Appearance' : '#E6E6E6'\n",
    "         }\n",
    "\n",
    "study_grp = study_grp.groupby('label').sum().sort_values('value',ascending=False).reset_index()\n",
    "study_grp['color'] = study_grp['label'].apply(lambda x: colors[x])\n",
    "study_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_study_label(df):\n",
    "    pio.templates.default = \"plotly_dark\"\n",
    "    fig = px.bar(df, x='label', y='value',\n",
    "             hover_data=['label', 'value'], color='label',\n",
    "             #labels={column: label},\n",
    "             color_discrete_map=colors,\n",
    "             text='value')\n",
    "    fig.update_layout(xaxis={'categoryorder':'array', 'categoryarray': df['label'],\n",
    "                             'title' : None, \n",
    "                             'showgrid':False},\n",
    "                      yaxis={'showgrid':False,\n",
    "                            'title' : 'Count'},\n",
    "                      showlegend=False,\n",
    "                     title = 'Study samples in train data')\n",
    "    fig.update_traces(textfont_size=16)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imageID  \\\n",
       "0  000a312787f2   \n",
       "1  000c3a3f293f   \n",
       "2  0012ff7358bc   \n",
       "3  001398f4ff4f   \n",
       "4  001bd15d1891   \n",
       "\n",
       "                                                                                                                                                         boxes  \\\n",
       "0  [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                          NaN   \n",
       "2        [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                            [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                           [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "\n",
       "                                                                                                     label  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                           none 1 0 0 1 1   \n",
       "2   opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                          opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4            opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "\n",
       "  StudyInstanceUID  negative  typical  indeterminate  atypical    target  \n",
       "0     5776db0cec75         0        1              0         0   typical  \n",
       "1     ff0879eb20ed         1        0              0         0  negative  \n",
       "2     9d514ce429a7         0        1              0         0   typical  \n",
       "3     28dddc8559b2         0        0              0         1  atypical  \n",
       "4     dfd9fdd85a3e         0        1              0         0   typical  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging study_level and image_level\n",
    "# rename id column in study_level to StudyInstanceUID\n",
    "study_df.rename(columns = {'id':'StudyInstanceUID'}, inplace = True)\n",
    "\n",
    "# remove _study from StudyInstanceUID\n",
    "study_df['StudyInstanceUID'] = study_df['StudyInstanceUID'].str.replace('_study', '')\n",
    "\n",
    "# merge\n",
    "df_train = pd.merge(image_df, study_df, on='StudyInstanceUID')\n",
    "\n",
    "# remove _image from id column\n",
    "df_train['id'] = df_train['id'].str.replace('_image', '')\n",
    "\n",
    "# rename id column as imageID\n",
    "df_train.rename(columns = {'id':'imageID'}, inplace = True)\n",
    "\n",
    "# renaming target columns\n",
    "df_train.rename(columns = {'Negative for Pneumonia':'negative'}, inplace = True)\n",
    "df_train.rename(columns = {'Typical Appearance':'typical'}, inplace = True)\n",
    "df_train.rename(columns = {'Indeterminate Appearance':'indeterminate'}, inplace = True)\n",
    "df_train.rename(columns = {'Atypical Appearance':'atypical'}, inplace = True)\n",
    "\n",
    "# Create a new target column\n",
    "categories = ['negative','typical','indeterminate','atypical']\n",
    "df = df_train[categories]\n",
    "df_train[\"target\"] = pd.Series(df.columns[np.where(df!=0)[1]])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNumber of train images: \u001b[32m 6334\n",
      "\n",
      "\u001b[33mNumber of test images: \u001b[32m 1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_jpg_directory = \"/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train\"\n",
    "test_jpg_directory = \"/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/test\"\n",
    "\n",
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "train_images_path = getImagePaths(train_jpg_directory)\n",
    "test_images_path = getImagePaths(test_jpg_directory)\n",
    "\n",
    "print(f\"{y_}Number of train images: {g_} {len(train_images_path)}\\n\")\n",
    "print(f\"{y_}Number of test images: {g_} {len(test_images_path)}\\n\")\n",
    "\n",
    "def getShape(data, images_paths):\n",
    "    shape = cv2.imread(images_paths[0]).shape\n",
    "    for image_path in images_paths:\n",
    "        image_shape=cv2.imread(image_path).shape\n",
    "        if (image_shape!=shape):\n",
    "            return data +\" - Different image shape\"\n",
    "        else:\n",
    "            return data +\" - Same image shape \" + str(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train - Same image shape (256, 256, 3)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getShape('train',train_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test - Same image shape (256, 256, 3)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getShape('test',test_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_images = DataFrame(train_images_path,columns=['train_images_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>imageID</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/d3ab6de09006.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/cb308b57472a.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/503563d744a1.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/bfb1ffabaaff.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ea56a7479090.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/36625db2640a.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/2b97a6619f32.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/68bc7bc6ad65.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/6713c2b6c0a6.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/4e94dc5b7c52.jpg</td>\n",
       "      <td>ne-Project/t</td>\n",
       "      <td>ne-Project/train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/d3ab6de09006.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/cb308b57472a.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/503563d744a1.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/bfb1ffabaaff.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ea56a7479090.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/36625db2640a.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/2b97a6619f32.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/68bc7bc6ad65.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/6713c2b6c0a6.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/4e94dc5b7c52.jpg   \n",
       "\n",
       "           imageID        Image_Name  \n",
       "0     ne-Project/t  ne-Project/train  \n",
       "1     ne-Project/t  ne-Project/train  \n",
       "2     ne-Project/t  ne-Project/train  \n",
       "3     ne-Project/t  ne-Project/train  \n",
       "4     ne-Project/t  ne-Project/train  \n",
       "...            ...               ...  \n",
       "6329  ne-Project/t  ne-Project/train  \n",
       "6330  ne-Project/t  ne-Project/train  \n",
       "6331  ne-Project/t  ne-Project/train  \n",
       "6332  ne-Project/t  ne-Project/train  \n",
       "6333  ne-Project/t  ne-Project/train  \n",
       "\n",
       "[6334 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_images['imageID'] = df_train_images['train_images_path'].str.slice(81,93)\n",
    "df_train_images['Image_Name'] = df_train_images['train_images_path'].str.slice(81,97)\n",
    "df_train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.merge(df_train,df_train_images, on='imageID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "      <th>target</th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [imageID, boxes, label, StudyInstanceUID, negative, typical, indeterminate, atypical, target, train_images_path, Image_Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final.drop(['boxes', 'label', 'StudyInstanceUID', 'typical', 'indeterminate', 'atypical', 'target', 'imageID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [negative, train_images_path, Image_Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If class_mode=\"binary\" there must be 2 classes. Found 0 classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_80300/1282886550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m train_generator = train_datagen.flow_from_dataframe(\n\u001b[0m\u001b[1;32m     26\u001b[0m                                         \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                         \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1078\u001b[0m           DeprecationWarning)\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     return DataFrameIterator(\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m       validate_filenames=True):\n\u001b[0;32m--> 555\u001b[0;31m     super(DataFrameIterator, self).__init__(\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# check that inputs match the required class_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# check which image files are valid and keep them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_valid_filepaths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                      .format(len(classes)))\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 raise ValueError('If class_mode=\"binary\" there must be 2 classes. '\n\u001b[0m\u001b[1;32m    209\u001b[0m                                  'Found {} classes.'.format(df[y_col].nunique()))\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# check values are string, list or tuple if class_mode is categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If class_mode=\"binary\" there must be 2 classes. Found 0 classes."
     ]
    }
   ],
   "source": [
    "df_train_final['negative'] = df_train_final['negative'].astype('str')\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.6, 1.3],\n",
    "    shear_range=0.3,\n",
    "    #zoom_range=[0.8, 1.0],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                                        dataframe=df_train_final,\n",
    "                                        directory='/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train',\n",
    "                                        x_col='Image_Name',\n",
    "                                        y_col='negative',\n",
    "                                        class_mode='binary',\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test data sets\n",
    "\n",
    "X = df_train_final.loc[:,'Image_Name']\n",
    "y = df_train_final.loc[:,'negative']\n",
    "\n",
    "# Split\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, \n",
    "                                                  test_size = 0.1, \n",
    "                                                  random_state = 27, \n",
    "                                                  stratify=y)\n",
    "\n",
    "# Train df\n",
    "df_train = pd.DataFrame(columns=['Image_Name','negative'])\n",
    "df_train['Image_Name'] = train_x\n",
    "df_train['negative'] = train_y\n",
    "\n",
    "# Test df\n",
    "df_test= pd.DataFrame(columns=['image_name','negative'])\n",
    "df_test['image_name'] = val_x\n",
    "df_test['negative'] = val_y\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/train/'\n",
    "\n",
    "# Images\n",
    "train_images = df_train.loc[:,'Image_Name']\n",
    "train_labels = df_train.loc[:,'negative']\n",
    "\n",
    "test_images = df_test.loc[:,'image_name']\n",
    "test_labels = df_test.loc[:,'negative']\n",
    "\n",
    "# Train images\n",
    "x_train = []\n",
    "for i in train_images:\n",
    "    image = home_path+i\n",
    "    img = cv2.imread(image)\n",
    "    x_train.append(img)\n",
    "\n",
    "# Train labels\n",
    "y_train = np.array(train_labels, dtype=\"float\")\n",
    "y_test = np.array(test_labels, dtype=\"float\")\n",
    "#y_train=keras.utils.to_categorical(train_labels)\n",
    "\n",
    "# Test images\n",
    "x_test = []\n",
    "for i in test_images:\n",
    "    image = home_path+i \n",
    "    img = cv2.imread(image)\n",
    "    x_test.append(img)\n",
    "\n",
    "# Test labels\n",
    "#y_test=keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Normalize images\n",
    "x_train = np.array(x_train, dtype=\"float\") / 255.0\n",
    "x_test = np.array(x_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train[:500]\n",
    "#y_train = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image dimensions to be used\n",
    "\n",
    "# specify first channels to represent color channels \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_train shape:\", x_train.shape)\n",
    "print(y_train.shape[0], \"train samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple sequential architecture for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architechture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking input Shape\n",
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Output Shape\n",
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile using Adam as the optimizer. \n",
    "optim = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2995035e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2995035e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 20:08:50.193572: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-23 20:08:50.201814: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7239WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2bfee9c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2bfee9c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "570/570 [==============================] - 62s 108ms/step - loss: 0.0000e+00 - accuracy: 0.7239 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 2/15\n",
      "570/570 [==============================] - 58s 102ms/step - loss: 0.0000e+00 - accuracy: 0.7301 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 3/15\n",
      "570/570 [==============================] - 60s 106ms/step - loss: 0.0000e+00 - accuracy: 0.7224 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 4/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7329 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 5/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7235 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 6/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7356 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 7/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7380 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 8/15\n",
      "570/570 [==============================] - 64s 113ms/step - loss: 0.0000e+00 - accuracy: 0.7235 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 9/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7180 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 10/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7302 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 11/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7264 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 12/15\n",
      "570/570 [==============================] - 65s 115ms/step - loss: 0.0000e+00 - accuracy: 0.7282 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 13/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7331 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 14/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7376 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 15/15\n",
      "570/570 [==============================] - 66s 116ms/step - loss: 0.0000e+00 - accuracy: 0.7323 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n"
     ]
    }
   ],
   "source": [
    "#Fit\n",
    "history = model.fit(x_train,y_train, epochs = 15, batch_size = 10, verbose = 1,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Model's accuracy for train and test sets\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model Analysis: \n",
    "Analyzing results from First Model: The Accuracy for all epochs seems to be around the 72% mark and does not seem to be improving. The accuracy for the validation set is the exact same across all epochs. We might need to test another model architecture to get better results than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Iteration of the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second model, we will take it a step further and add attributes to the nodes such as the kernel regularizer. We will also add droputs and increase the Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build CNN with dropout model\n",
    "model2 = Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "                        kernel_regularizer='l2', input_shape=(256,256,3)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(32,kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(32,kernel_size=5,strides=2,padding='same',\n",
    "                        activation='relu', kernel_regularizer='l2'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "# Add dropouts to the model\n",
    "model2.add(layers.Dropout(0.4))\n",
    "model2.add(layers.Conv2D(64, kernel_size=(3, 3), strides=2,padding='same', \n",
    "                       activation='relu', kernel_regularizer='l2'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(64, kernel_size=(3, 3), strides=2,padding='same', \n",
    "                        activation='relu', kernel_regularizer='l2'))\n",
    "# Add dropouts and Dense layers\n",
    "model2.add(layers.Dropout(0.4))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(units=128, activation='relu', kernel_regularizer='l2'))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Dense(units=64, activation='relu', kernel_regularizer='l2'))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Dense(units=1, activation='sigmoid', kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 254, 254, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 252, 252, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 252, 252, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 126, 126, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 624,577\n",
      "Trainable params: 624,257\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_5_input')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Model2 input shape\n",
    "model2.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_7')>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Model2 output shape\n",
    "model2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 21:24:48.456472: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-23 21:24:48.477932: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17f328820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17f328820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "42/57 [=====================>........] - ETA: 8:44 - loss: 7.5106 - accuracy: 0.6838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_78709/4234195045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Fit Model 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history2 = model2.fit(x_train,y_train, epochs = 15, batch_size = 100, verbose = 1,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     validation_data = (x_test, y_test))\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Compile Model 2\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "#Fit Model 2\n",
    "history2 = model2.fit(x_train,y_train, epochs = 15, batch_size = 100, verbose = 1,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Model2's accuracy for train and test sets\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy'sl)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model2.evaluate(test_generator)\n",
    "print()\n",
    "print('Model Loss: {}%'.format(scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
