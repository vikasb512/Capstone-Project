{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convolutional Neural Network Classification Model:\n",
    "\n",
    "\n",
    "My intent with this project was to build a simple deep learning neural network that would be capable of performing binary classification on Chest X-Ray Images s from Kaggle.com. I had to import a module that would serve as an operating system interface from python in the form of os in order to interact directly with the directories located on my computer. Keras was used extensively in this project in order to make use of all of its deep learning capabilities. Numpy was used in the manipulation of images in the form of arrays. Pandas and Matplotlib, were utilized in the exploratory phase of this project in order to visualize the data.\n",
    "\n",
    "I started with importing the necessary modules and libraries needed for this project. I then went ahead and performed the rudimentary data exploration phase by reading in some images as examples of what the data looks like. I also assigned certain directories to their respective variables in order to make use of them in the visualization and deep learning model building stages. I then went ahead and created simple histograms and pie charts comparing people with and without pneumonia lung disease in each of the 3 directories (train, test, and val). Arguably, the most difficult part of this project was constructing the deep learning convolutional neural network to classify the images. I played around with certain parameters in terms of batch size and epochs. There were a lot of moving pieces when it came to initializing this model in order to make it the most efficient possible. I made use of sigmoid and relu activation functions.In conclusion, I would say that the models turned out unsatisfactory for the use case, and I'd like expand on this work in the future and see if there is any way I could descrease the loss at all and increase the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "\n",
    "\n",
    "#from pydicom import dcmread\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "res = Style.RESET_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTrain image level csv shape : (6334, 4)\u001b[0m\n",
      "\u001b[32mTrain study level csv shape : (6054, 5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "image_df = pd.read_csv('train_image_level.csv', index_col=None)\n",
    "study_df = pd.read_csv('train_study_level.csv', index_col=None)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"{y_}Train image level csv shape : {image_df.shape}{res}\\n{g_}Train study level csv shape : {study_df.shape}{res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00292f8c37bd_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005057b3f880_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0051d9b12e72_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>ffcb4630f46f_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>ffe4d6e8fbb0_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>ffe94fcb14fa_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>ffebf1ef4a9c_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>fff649d65f62_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6054 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  Negative for Pneumonia  Typical Appearance  \\\n",
       "0     00086460a852_study                       0                   1   \n",
       "1     000c9c05fd14_study                       0                   0   \n",
       "2     00292f8c37bd_study                       1                   0   \n",
       "3     005057b3f880_study                       1                   0   \n",
       "4     0051d9b12e72_study                       0                   0   \n",
       "...                  ...                     ...                 ...   \n",
       "6049  ffcb4630f46f_study                       0                   1   \n",
       "6050  ffe4d6e8fbb0_study                       0                   1   \n",
       "6051  ffe94fcb14fa_study                       0                   1   \n",
       "6052  ffebf1ef4a9c_study                       0                   1   \n",
       "6053  fff649d65f62_study                       0                   1   \n",
       "\n",
       "      Indeterminate Appearance  Atypical Appearance  \n",
       "0                            0                    0  \n",
       "1                            0                    1  \n",
       "2                            0                    0  \n",
       "3                            0                    0  \n",
       "4                            0                    1  \n",
       "...                        ...                  ...  \n",
       "6049                         0                    0  \n",
       "6050                         0                    0  \n",
       "6051                         0                    0  \n",
       "6052                         0                    0  \n",
       "6053                         0                    0  \n",
       "\n",
       "[6054 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2_image</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc_image</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f_image</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891_image</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961_image</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609</td>\n",
       "      <td>7eed9af03814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680_image</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f_image</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0     000a312787f2_image   \n",
       "1     000c3a3f293f_image   \n",
       "2     0012ff7358bc_image   \n",
       "3     001398f4ff4f_image   \n",
       "4     001bd15d1891_image   \n",
       "...                  ...   \n",
       "6329  ffcc6edd9445_image   \n",
       "6330  ffd91a2c4ca0_image   \n",
       "6331  ffd9b6cf2961_image   \n",
       "6332  ffdc682f7680_image   \n",
       "6333  ffe942c8655f_image   \n",
       "\n",
       "                                                                                                                                                                                                                                    boxes  \\\n",
       "0                                                                             [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                   [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                                                                                                       [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                                                                                                      [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "...                                                                                                                                                                                                                                   ...   \n",
       "6329                                                                                                                                                                                                                                  NaN   \n",
       "6330                                                                                                                                                                                                                                  NaN   \n",
       "6331  [{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]   \n",
       "6332                                                                           [{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]   \n",
       "6333                                                                                  [{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]   \n",
       "\n",
       "                                                                                                                                                                               label  \\\n",
       "0                                                                            opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                                                                                                     none 1 0 0 1 1   \n",
       "2                                                                             opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                                                                                                    opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4                                                                                      opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "...                                                                                                                                                                              ...   \n",
       "6329                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6330                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609   \n",
       "6332                                                               opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048   \n",
       "6333                                                                              opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119   \n",
       "\n",
       "     StudyInstanceUID  \n",
       "0        5776db0cec75  \n",
       "1        ff0879eb20ed  \n",
       "2        9d514ce429a7  \n",
       "3        28dddc8559b2  \n",
       "4        dfd9fdd85a3e  \n",
       "...               ...  \n",
       "6329     7e6c68462e06  \n",
       "6330     8332bdaddb6e  \n",
       "6331     7eed9af03814  \n",
       "6332     a0cb0b96fb3d  \n",
       "6333     7d82d53204b8  \n",
       "\n",
       "[6334 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Typical Appearance</td>\n",
       "      <td>2855</td>\n",
       "      <td>#DCD427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative for Pneumonia</td>\n",
       "      <td>1676</td>\n",
       "      <td>#0092CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indeterminate Appearance</td>\n",
       "      <td>1049</td>\n",
       "      <td>#CC3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atypical Appearance</td>\n",
       "      <td>474</td>\n",
       "      <td>#E6E6E6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  value    color\n",
       "0        Typical Appearance   2855  #DCD427\n",
       "1    Negative for Pneumonia   1676  #0092CC\n",
       "2  Indeterminate Appearance   1049  #CC3333\n",
       "3       Atypical Appearance    474  #E6E6E6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_grp = pd.melt(study_df, id_vars=list(study_df.columns)[:1], value_vars=list(study_df.columns)[1:],\n",
    "             var_name='label', value_name='value')\n",
    "study_grp = study_grp.loc[study_grp['value']!=0]\n",
    "colors = {'Typical Appearance' : '#DCD427',\n",
    "'Negative for Pneumonia' : '#0092CC',\n",
    "'Indeterminate Appearance' : '#CC3333',\n",
    "#'Atypical Appearance' : '#779933',\n",
    "          'Atypical Appearance' : '#E6E6E6'\n",
    "         }\n",
    "\n",
    "study_grp = study_grp.groupby('label').sum().sort_values('value',ascending=False).reset_index()\n",
    "study_grp['color'] = study_grp['label'].apply(lambda x: colors[x])\n",
    "study_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_study_label(df):\n",
    "    pio.templates.default = \"plotly_dark\"\n",
    "    fig = px.bar(df, x='label', y='value',\n",
    "             hover_data=['label', 'value'], color='label',\n",
    "             #labels={column: label},\n",
    "             color_discrete_map=colors,\n",
    "             text='value')\n",
    "    fig.update_layout(xaxis={'categoryorder':'array', 'categoryarray': df['label'],\n",
    "                             'title' : None, \n",
    "                             'showgrid':False},\n",
    "                      yaxis={'showgrid':False,\n",
    "                            'title' : 'Count'},\n",
    "                      showlegend=False,\n",
    "                     title = 'Study samples in train data')\n",
    "    fig.update_traces(textfont_size=16)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imageID  \\\n",
       "0  000a312787f2   \n",
       "1  000c3a3f293f   \n",
       "2  0012ff7358bc   \n",
       "3  001398f4ff4f   \n",
       "4  001bd15d1891   \n",
       "\n",
       "                                                                                                                                                         boxes  \\\n",
       "0  [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                          NaN   \n",
       "2        [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                            [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                           [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "\n",
       "                                                                                                     label  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                           none 1 0 0 1 1   \n",
       "2   opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                          opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4            opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "\n",
       "  StudyInstanceUID  negative  typical  indeterminate  atypical    target  \n",
       "0     5776db0cec75         0        1              0         0   typical  \n",
       "1     ff0879eb20ed         1        0              0         0  negative  \n",
       "2     9d514ce429a7         0        1              0         0   typical  \n",
       "3     28dddc8559b2         0        0              0         1  atypical  \n",
       "4     dfd9fdd85a3e         0        1              0         0   typical  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging study_level and image_level\n",
    "# rename id column in study_level to StudyInstanceUID\n",
    "study_df.rename(columns = {'id':'StudyInstanceUID'}, inplace = True)\n",
    "\n",
    "# remove _study from StudyInstanceUID\n",
    "study_df['StudyInstanceUID'] = study_df['StudyInstanceUID'].str.replace('_study', '')\n",
    "\n",
    "# merge\n",
    "df_train = pd.merge(image_df, study_df, on='StudyInstanceUID')\n",
    "\n",
    "# remove _image from id column\n",
    "df_train['id'] = df_train['id'].str.replace('_image', '')\n",
    "\n",
    "# rename id column as imageID\n",
    "df_train.rename(columns = {'id':'imageID'}, inplace = True)\n",
    "\n",
    "# renaming target columns\n",
    "df_train.rename(columns = {'Negative for Pneumonia':'negative'}, inplace = True)\n",
    "df_train.rename(columns = {'Typical Appearance':'typical'}, inplace = True)\n",
    "df_train.rename(columns = {'Indeterminate Appearance':'indeterminate'}, inplace = True)\n",
    "df_train.rename(columns = {'Atypical Appearance':'atypical'}, inplace = True)\n",
    "\n",
    "# Create a new target column\n",
    "categories = ['negative','typical','indeterminate','atypical']\n",
    "df = df_train[categories]\n",
    "df_train[\"target\"] = pd.Series(df.columns[np.where(df!=0)[1]])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNumber of train images: \u001b[32m 6334\n",
      "\n",
      "\u001b[33mNumber of test images: \u001b[32m 1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_jpg_directory = \"/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train\"\n",
    "test_jpg_directory = \"/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/test\"\n",
    "\n",
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "train_images_path = getImagePaths(train_jpg_directory)\n",
    "test_images_path = getImagePaths(test_jpg_directory)\n",
    "\n",
    "print(f\"{y_}Number of train images: {g_} {len(train_images_path)}\\n\")\n",
    "print(f\"{y_}Number of test images: {g_} {len(test_images_path)}\\n\")\n",
    "\n",
    "def getShape(data, images_paths):\n",
    "    shape = cv2.imread(images_paths[0]).shape\n",
    "    for image_path in images_paths:\n",
    "        image_shape=cv2.imread(image_path).shape\n",
    "        if (image_shape!=shape):\n",
    "            return data +\" - Different image shape\"\n",
    "        else:\n",
    "            return data +\" - Same image shape \" + str(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train - Same image shape (256, 256, 3)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getShape('train',train_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test - Same image shape (256, 256, 3)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getShape('test',test_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_images = DataFrame(train_images_path,columns=['train_images_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>imageID</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/d3ab6de09006.jpg</td>\n",
       "      <td>d3ab6de09006</td>\n",
       "      <td>d3ab6de09006.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/cb308b57472a.jpg</td>\n",
       "      <td>cb308b57472a</td>\n",
       "      <td>cb308b57472a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/503563d744a1.jpg</td>\n",
       "      <td>503563d744a1</td>\n",
       "      <td>503563d744a1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/bfb1ffabaaff.jpg</td>\n",
       "      <td>bfb1ffabaaff</td>\n",
       "      <td>bfb1ffabaaff.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ea56a7479090.jpg</td>\n",
       "      <td>ea56a7479090</td>\n",
       "      <td>ea56a7479090.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/36625db2640a.jpg</td>\n",
       "      <td>36625db2640a</td>\n",
       "      <td>36625db2640a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/2b97a6619f32.jpg</td>\n",
       "      <td>2b97a6619f32</td>\n",
       "      <td>2b97a6619f32.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/68bc7bc6ad65.jpg</td>\n",
       "      <td>68bc7bc6ad65</td>\n",
       "      <td>68bc7bc6ad65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/6713c2b6c0a6.jpg</td>\n",
       "      <td>6713c2b6c0a6</td>\n",
       "      <td>6713c2b6c0a6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/4e94dc5b7c52.jpg</td>\n",
       "      <td>4e94dc5b7c52</td>\n",
       "      <td>4e94dc5b7c52.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/d3ab6de09006.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/cb308b57472a.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/503563d744a1.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/bfb1ffabaaff.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ea56a7479090.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/36625db2640a.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/2b97a6619f32.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/68bc7bc6ad65.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/6713c2b6c0a6.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/4e94dc5b7c52.jpg   \n",
       "\n",
       "           imageID        Image_Name  \n",
       "0     d3ab6de09006  d3ab6de09006.jpg  \n",
       "1     cb308b57472a  cb308b57472a.jpg  \n",
       "2     503563d744a1  503563d744a1.jpg  \n",
       "3     bfb1ffabaaff  bfb1ffabaaff.jpg  \n",
       "4     ea56a7479090  ea56a7479090.jpg  \n",
       "...            ...               ...  \n",
       "6329  36625db2640a  36625db2640a.jpg  \n",
       "6330  2b97a6619f32  2b97a6619f32.jpg  \n",
       "6331  68bc7bc6ad65  68bc7bc6ad65.jpg  \n",
       "6332  6713c2b6c0a6  6713c2b6c0a6.jpg  \n",
       "6333  4e94dc5b7c52  4e94dc5b7c52.jpg  \n",
       "\n",
       "[6334 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_images['imageID'] = df_train_images['train_images_path'].str.slice(98,110)\n",
    "df_train_images['Image_Name'] = df_train_images['train_images_path'].str.slice(98,114)\n",
    "df_train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.merge(df_train,df_train_images, on='imageID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "      <th>target</th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg</td>\n",
       "      <td>000a312787f2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg</td>\n",
       "      <td>000c3a3f293f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg</td>\n",
       "      <td>0012ff7358bc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>atypical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg</td>\n",
       "      <td>001398f4ff4f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg</td>\n",
       "      <td>001bd15d1891.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>ffcc6edd9445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>7e6c68462e06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg</td>\n",
       "      <td>ffcc6edd9445.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>ffd91a2c4ca0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>8332bdaddb6e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg</td>\n",
       "      <td>ffd91a2c4ca0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>ffd9b6cf2961</td>\n",
       "      <td>[{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]</td>\n",
       "      <td>opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609</td>\n",
       "      <td>7eed9af03814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg</td>\n",
       "      <td>ffd9b6cf2961.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>ffdc682f7680</td>\n",
       "      <td>[{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]</td>\n",
       "      <td>opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048</td>\n",
       "      <td>a0cb0b96fb3d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg</td>\n",
       "      <td>ffdc682f7680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>ffe942c8655f</td>\n",
       "      <td>[{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]</td>\n",
       "      <td>opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119</td>\n",
       "      <td>7d82d53204b8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>typical</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg</td>\n",
       "      <td>ffe942c8655f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           imageID  \\\n",
       "0     000a312787f2   \n",
       "1     000c3a3f293f   \n",
       "2     0012ff7358bc   \n",
       "3     001398f4ff4f   \n",
       "4     001bd15d1891   \n",
       "...            ...   \n",
       "6329  ffcc6edd9445   \n",
       "6330  ffd91a2c4ca0   \n",
       "6331  ffd9b6cf2961   \n",
       "6332  ffdc682f7680   \n",
       "6333  ffe942c8655f   \n",
       "\n",
       "                                                                                                                                                                                                                                    boxes  \\\n",
       "0                                                                             [{'x': 789.28836, 'y': 582.43035, 'width': 1026.65662, 'height': 1917.30292}, {'x': 2245.91208, 'y': 591.20528, 'width': 1094.66162, 'height': 1761.54944}]   \n",
       "1                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                   [{'x': 677.42216, 'y': 197.97662, 'width': 867.79767, 'height': 999.78214}, {'x': 1792.69064, 'y': 402.5525, 'width': 617.02734, 'height': 1204.358}]   \n",
       "3                                                                                                                                                                       [{'x': 2729, 'y': 2181.33331, 'width': 948.00012, 'height': 604}]   \n",
       "4                                                                                                      [{'x': 623.23328, 'y': 1050, 'width': 714, 'height': 1106}, {'x': 2578.56661, 'y': 998.66667, 'width': 662.66667, 'height': 1120}]   \n",
       "...                                                                                                                                                                                                                                   ...   \n",
       "6329                                                                                                                                                                                                                                  NaN   \n",
       "6330                                                                                                                                                                                                                                  NaN   \n",
       "6331  [{'x': 2197.38566, 'y': 841.07361, 'width': 316.41699, 'height': 451.63758}, {'x': 2375.87717, 'y': 1830.89015, 'width': 267.7373, 'height': 305.59912}, {'x': 707.25199, 'y': 722.07926, 'width': 392.14044, 'height': 849.18683}]   \n",
       "6332                                                                           [{'x': 2729.27083, 'y': 332.26044, 'width': 1496.25016, 'height': 2604.58334}, {'x': 1005.8125, 'y': 1584.67711, 'width': 662.22913, 'height': 775.83337}]   \n",
       "6333                                                                                  [{'x': 208.86463, 'y': 91.53448, 'width': 450.96747, 'height': 628.05473}, {'x': 755.52522, 'y': 144.33069, 'width': 427.8692, 'height': 547.7605}]   \n",
       "\n",
       "                                                                                                                                                                               label  \\\n",
       "0                                                                            opacity 1 789.28836 582.43035 1815.94498 2499.73327 opacity 1 2245.91208 591.20528 3340.5737 2352.75472   \n",
       "1                                                                                                                                                                     none 1 0 0 1 1   \n",
       "2                                                                             opacity 1 677.42216 197.97662 1545.21983 1197.75876 opacity 1 1792.69064 402.5525 2409.71798 1606.9105   \n",
       "3                                                                                                                                    opacity 1 2729 2181.33331 3677.00012 2785.33331   \n",
       "4                                                                                      opacity 1 623.23328 1050 1337.23328 2156 opacity 1 2578.56661 998.66667 3241.23328 2118.66667   \n",
       "...                                                                                                                                                                              ...   \n",
       "6329                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6330                                                                                                                                                                  none 1 0 0 1 1   \n",
       "6331  opacity 1 2197.38566 841.07361 2513.80265 1292.71119 opacity 1 2375.87717 1830.89015 2643.6144700000004 2136.48927 opacity 1 707.25199 722.07926 1099.3924299999999 1571.26609   \n",
       "6332                                                               opacity 1 2729.27083 332.26044 4225.52099 2936.84378 opacity 1 1005.8125 1584.67711 1668.0416300000002 2360.51048   \n",
       "6333                                                                              opacity 1 208.86463 91.53448 659.8321 719.58921 opacity 1 755.52522 144.33069 1183.39442 692.09119   \n",
       "\n",
       "     StudyInstanceUID  negative  typical  indeterminate  atypical    target  \\\n",
       "0        5776db0cec75         0        1              0         0   typical   \n",
       "1        ff0879eb20ed         1        0              0         0  negative   \n",
       "2        9d514ce429a7         0        1              0         0   typical   \n",
       "3        28dddc8559b2         0        0              0         1  atypical   \n",
       "4        dfd9fdd85a3e         0        1              0         0   typical   \n",
       "...               ...       ...      ...            ...       ...       ...   \n",
       "6329     7e6c68462e06         1        0              0         0  negative   \n",
       "6330     8332bdaddb6e         1        0              0         0  negative   \n",
       "6331     7eed9af03814         0        1              0         0   typical   \n",
       "6332     a0cb0b96fb3d         0        1              0         0   typical   \n",
       "6333     7d82d53204b8         0        1              0         0   typical   \n",
       "\n",
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg   \n",
       "\n",
       "            Image_Name  \n",
       "0     000a312787f2.jpg  \n",
       "1     000c3a3f293f.jpg  \n",
       "2     0012ff7358bc.jpg  \n",
       "3     001398f4ff4f.jpg  \n",
       "4     001bd15d1891.jpg  \n",
       "...                ...  \n",
       "6329  ffcc6edd9445.jpg  \n",
       "6330  ffd91a2c4ca0.jpg  \n",
       "6331  ffd9b6cf2961.jpg  \n",
       "6332  ffdc682f7680.jpg  \n",
       "6333  ffe942c8655f.jpg  \n",
       "\n",
       "[6334 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final.drop(['boxes', 'label', 'StudyInstanceUID', 'typical', 'indeterminate', 'atypical', 'target', 'imageID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>train_images_path</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg</td>\n",
       "      <td>000a312787f2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg</td>\n",
       "      <td>000c3a3f293f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg</td>\n",
       "      <td>0012ff7358bc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg</td>\n",
       "      <td>001398f4ff4f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg</td>\n",
       "      <td>001bd15d1891.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg</td>\n",
       "      <td>ffcc6edd9445.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg</td>\n",
       "      <td>ffd91a2c4ca0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg</td>\n",
       "      <td>ffd9b6cf2961.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg</td>\n",
       "      <td>ffdc682f7680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg</td>\n",
       "      <td>ffe942c8655f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6334 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative  \\\n",
       "0            0   \n",
       "1            1   \n",
       "2            0   \n",
       "3            0   \n",
       "4            0   \n",
       "...        ...   \n",
       "6329         1   \n",
       "6330         1   \n",
       "6331         0   \n",
       "6332         0   \n",
       "6333         0   \n",
       "\n",
       "                                                                                                       train_images_path  \\\n",
       "0     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000a312787f2.jpg   \n",
       "1     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/000c3a3f293f.jpg   \n",
       "2     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/0012ff7358bc.jpg   \n",
       "3     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001398f4ff4f.jpg   \n",
       "4     /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/001bd15d1891.jpg   \n",
       "...                                                                                                                  ...   \n",
       "6329  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffcc6edd9445.jpg   \n",
       "6330  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd91a2c4ca0.jpg   \n",
       "6331  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffd9b6cf2961.jpg   \n",
       "6332  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffdc682f7680.jpg   \n",
       "6333  /Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/ffe942c8655f.jpg   \n",
       "\n",
       "            Image_Name  \n",
       "0     000a312787f2.jpg  \n",
       "1     000c3a3f293f.jpg  \n",
       "2     0012ff7358bc.jpg  \n",
       "3     001398f4ff4f.jpg  \n",
       "4     001bd15d1891.jpg  \n",
       "...                ...  \n",
       "6329  ffcc6edd9445.jpg  \n",
       "6330  ffd91a2c4ca0.jpg  \n",
       "6331  ffd9b6cf2961.jpg  \n",
       "6332  ffdc682f7680.jpg  \n",
       "6333  ffe942c8655f.jpg  \n",
       "\n",
       "[6334 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6334 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "df_train_final['negative'] = df_train_final['negative'].astype('str')\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.6, 1.3],\n",
    "    shear_range=0.3,\n",
    "    #zoom_range=[0.8, 1.0],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                                        dataframe=df_train_final,\n",
    "                                        directory='/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train',\n",
    "                                        x_col='Image_Name',\n",
    "                                        y_col='negative',\n",
    "                                        class_mode='binary',\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test data sets\n",
    "\n",
    "X = df_train_final.loc[:,'Image_Name']\n",
    "y = df_train_final.loc[:,'negative']\n",
    "\n",
    "# Split\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, \n",
    "                                                  test_size = 0.1, \n",
    "                                                  random_state = 27, \n",
    "                                                  stratify=y)\n",
    "\n",
    "# Train df\n",
    "df_train = pd.DataFrame(columns=['Image_Name','negative'])\n",
    "df_train['Image_Name'] = train_x\n",
    "df_train['negative'] = train_y\n",
    "\n",
    "# Test df\n",
    "df_test= pd.DataFrame(columns=['image_name','negative'])\n",
    "df_test['image_name'] = val_x\n",
    "df_test['negative'] = val_y\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7c46483f6ef9.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0edcec25f01f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66a513ecac8f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00e3a7e91a34.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72039153a0dd.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2da7581bab1e.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>3d6c5fa4b95e.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>35ad423bca61.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>c8f42ce79d67.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>3b31c91dd63b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name negative\n",
       "0    7c46483f6ef9.jpg        0\n",
       "1    0edcec25f01f.jpg        0\n",
       "2    66a513ecac8f.jpg        0\n",
       "3    00e3a7e91a34.jpg        1\n",
       "4    72039153a0dd.jpg        0\n",
       "..                ...      ...\n",
       "629  2da7581bab1e.jpg        0\n",
       "630  3d6c5fa4b95e.jpg        0\n",
       "631  35ad423bca61.jpg        0\n",
       "632  c8f42ce79d67.jpg        1\n",
       "633  3b31c91dd63b.jpg        0\n",
       "\n",
       "[634 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/Users/vikasbansal/Desktop/ds/Capstone Project/dsc-data-science-env-config/Capstone-Project/train/'\n",
    "\n",
    "# Images\n",
    "train_images = df_train.loc[:,'Image_Name']\n",
    "train_labels = df_train.loc[:,'negative']\n",
    "\n",
    "test_images = df_test.loc[:,'image_name']\n",
    "test_labels = df_test.loc[:,'negative']\n",
    "\n",
    "# Train images\n",
    "x_train = []\n",
    "for i in train_images:\n",
    "    image = home_path+i\n",
    "    img = cv2.imread(image)\n",
    "    x_train.append(img)\n",
    "\n",
    "# Train and Test labels\n",
    "y_train = np.array(train_labels, dtype=\"float\")\n",
    "y_test = np.array(test_labels, dtype=\"float\")\n",
    "y_train=keras.utils.to_categorical(train_labels)\n",
    "y_test=keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Test images\n",
    "x_test = []\n",
    "for i in test_images:\n",
    "    image = home_path+i \n",
    "    img = cv2.imread(image)\n",
    "    x_test.append(img)\n",
    "\n",
    "# Normalize images\n",
    "x_train = np.array(x_train, dtype=\"float\") / 255.0\n",
    "x_test = np.array(x_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train[:500]\n",
    "#y_train = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5695    1\n",
       "5696    0\n",
       "5697    0\n",
       "5698    0\n",
       "5699    0\n",
       "Name: negative, Length: 5700, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 256, 256, 3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image dimensions to be used\n",
    "\n",
    "# specify first channels to represent color channels \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(train_labels[:,1], (5700,1))\n",
    "y_test = np.reshape(test_labels[:,1], (624,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (5700, 256, 256, 3)\n",
      "5700 train samples\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", x_train.shape)\n",
    "print(y_train.shape[0], \"train samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a Function for Confusion Matrix, for analysis during our modeling process\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    '''Plots a confusion matrix'''\n",
    "    class_names = ['Normal','Pneumonia']\n",
    "\n",
    "    plt.grid(b=None)\n",
    "    cmap=plt.cm.Blues  \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.imshow(cnf_matrix, cmap=cmap) \n",
    "\n",
    "    # Add title and axis labels\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # Add appropriate axis scales\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "\n",
    "    # Add labels to each cell\n",
    "    thresh = cnf_matrix.max() / 2. # Used for text coloring below\n",
    "    \n",
    "    # Here we iterate through the confusion matrix and append labels to our visualization \n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment='center',\n",
    "                 fontsize=16,\n",
    "                 color='white' if cnf_matrix[i, j] > thresh else 'black')\n",
    "\n",
    "    \n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple sequential architecture for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architechture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_input')>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking input Shape\n",
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'activation_4')>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Output Shape\n",
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile using Adam as the optimizer. \n",
    "optim = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 19:56:42.386489: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-03 19:56:42.393336: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17ff86940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x17ff86940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7255WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x148169700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x148169700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "570/570 [==============================] - 63s 109ms/step - loss: 0.0000e+00 - accuracy: 0.7255 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 2/15\n",
      "570/570 [==============================] - 58s 102ms/step - loss: 0.0000e+00 - accuracy: 0.7273 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 3/15\n",
      "570/570 [==============================] - 61s 108ms/step - loss: 0.0000e+00 - accuracy: 0.7259 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 4/15\n",
      "570/570 [==============================] - 62s 108ms/step - loss: 0.0000e+00 - accuracy: 0.7259 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 5/15\n",
      "570/570 [==============================] - 61s 107ms/step - loss: 0.0000e+00 - accuracy: 0.7341 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 6/15\n",
      "570/570 [==============================] - 62s 109ms/step - loss: 0.0000e+00 - accuracy: 0.7290 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 7/15\n",
      "570/570 [==============================] - 63s 110ms/step - loss: 0.0000e+00 - accuracy: 0.7208 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 8/15\n",
      "570/570 [==============================] - 68s 119ms/step - loss: 0.0000e+00 - accuracy: 0.7359 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 9/15\n",
      "570/570 [==============================] - 65s 113ms/step - loss: 0.0000e+00 - accuracy: 0.7204 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 10/15\n",
      "570/570 [==============================] - 66s 115ms/step - loss: 0.0000e+00 - accuracy: 0.7318 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 11/15\n",
      "570/570 [==============================] - 64s 113ms/step - loss: 0.0000e+00 - accuracy: 0.7268 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 12/15\n",
      "570/570 [==============================] - 64s 112ms/step - loss: 0.0000e+00 - accuracy: 0.7248 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 13/15\n",
      "570/570 [==============================] - 63s 110ms/step - loss: 0.0000e+00 - accuracy: 0.7286 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 14/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7106 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 15/15\n",
      "570/570 [==============================] - 65s 114ms/step - loss: 0.0000e+00 - accuracy: 0.7339 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n"
     ]
    }
   ],
   "source": [
    "#Fit\n",
    "history = model.fit(x_train,y_train, epochs = 15, batch_size = 10, verbose = 1,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Model's accuracy for train and test sets\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model Analysis: \n",
    "Analyzing results from First Model: The Accuracy for all epochs seems to be around the 72% mark and does not seem to be improving. The accuracy for the validation set is the exact same across all epochs. We might need to test another model architecture to get better results than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Iteration of the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second model, we will take it a step further and add attributes to the nodes such as the kernel regularizer. We will also add droputs and increase the Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build CNN with dropout model\n",
    "#model2 = Sequential()\n",
    "#model2.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "#                        kernel_regularizer='l2', input_shape=(256,256,3)))\n",
    "#model2.add(layers.BatchNormalization())\n",
    "#model2.add(layers.Conv2D(32,kernel_size=(3, 3), activation='relu'))\n",
    "#model2.add(layers.BatchNormalization())\n",
    "#model2.add(layers.Conv2D(32,kernel_size=5,strides=2,padding='same',\n",
    "#                        activation='relu', kernel_regularizer='l2'))\n",
    "#model2.add(layers.MaxPooling2D((2, 2)))\n",
    "#model2.add(layers.BatchNormalization())\n",
    "# Add dropouts to the model\n",
    "#model2.add(layers.Dropout(0.4))\n",
    "#model2.add(layers.Conv2D(64, kernel_size=(3, 3), strides=2,padding='same', \n",
    "#                       activation='relu', kernel_regularizer='l2'))\n",
    "#model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model2.add(layers.BatchNormalization())\n",
    "#model2.add(layers.Conv2D(64, kernel_size=(3, 3), strides=2,padding='same', \n",
    "#                        activation='relu', kernel_regularizer='l2'))\n",
    "# Add dropouts and Dense layers\n",
    "#model2.add(layers.Dropout(0.4))\n",
    "#model2.add(layers.Flatten())\n",
    "#model2.add(layers.Dense(units=128, activation='relu', kernel_regularizer='l2'))\n",
    "#model2.add(layers.Dropout(0.2))\n",
    "#model2.add(layers.Dense(units=64, activation='relu', kernel_regularizer='l2'))\n",
    "#model2.add(layers.Dropout(0.2))\n",
    "#model2.add(layers.Dense(units=1, activation='sigmoid', kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_6_input')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Model2 input shape\n",
    "model2.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'activation_14')>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Model2 output shape\n",
    "model2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 21:36:32.727724: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-03 21:36:32.733281: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x296317af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x296317af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7203WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x147a37b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x147a37b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "57/57 [==============================] - 120s 2s/step - loss: 0.0000e+00 - accuracy: 0.7204 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7411 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 114s 2s/step - loss: 0.0000e+00 - accuracy: 0.7355 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 114s 2s/step - loss: 0.0000e+00 - accuracy: 0.7315 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 113s 2s/step - loss: 0.0000e+00 - accuracy: 0.7308 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 115s 2s/step - loss: 0.0000e+00 - accuracy: 0.7251 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7218 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 117s 2s/step - loss: 0.0000e+00 - accuracy: 0.7247 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7311 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 116s 2s/step - loss: 0.0000e+00 - accuracy: 0.7140 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 120s 2s/step - loss: 0.0000e+00 - accuracy: 0.7258 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 118s 2s/step - loss: 0.0000e+00 - accuracy: 0.7289 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 115s 2s/step - loss: 0.0000e+00 - accuracy: 0.7257 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 118s 2s/step - loss: 0.0000e+00 - accuracy: 0.7289 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 114s 2s/step - loss: 0.0000e+00 - accuracy: 0.7216 - val_loss: 0.0000e+00 - val_accuracy: 0.7256\n"
     ]
    }
   ],
   "source": [
    "#Compile Model 2\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "#Fit Model 2\n",
    "history2 = model2.fit(x_train,y_train, epochs = 15, batch_size = 100, verbose = 1,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Model2's accuracy for train and test sets\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_41294/3718728209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_41294/2225487458.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=input_shape))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.4))\n",
    "model3.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.4))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.4))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(64, activation='relu'))\n",
    "model3.add(layers.Dropout(0.2))\n",
    "model3.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 124, 124, 32)      16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,722,337\n",
      "Trainable params: 3,722,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_3_input')>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_3')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-03 22:42:55.115595: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-03 22:42:55.124075: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x1693e9160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x1693e9160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x17fcc49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x17fcc49d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/pzsp3v213pj9s0b3l3qzwwgm0000gn/T/ipykernel_41294/3987379963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history3 = model3.fit(x_train,y_train, epochs = 15, batch_size = 10, verbose = 0,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data = (x_test, y_test))\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_ml/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train,y_train, epochs = 15, batch_size = 10, verbose = 0,\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
